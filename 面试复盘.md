

## 算法

- 动态规划1，0 的grid 表格中，找到最大的正方型
- 两个无序的数组合并成一个有序数组



```
    "JVM": {"weight": 0.3, "subtopics": ["GC", "内存模型", "类加载"]},
    "并发编程": {"weight": 0.25, "subtopics": ["线程池", "锁机制", "原子类"]},
    "Spring框架": {"weight": 0.2, "subtopics": ["IoC", "AOP", "事务管理"]},
    "分布式系统": {"weight": 0.15, "subtopics": ["CAP理论", "分布式事务"]},
    "设计模式": {"weight": 0.1, "subtopics": ["单例", "工厂", "代理"]}
```

```
    评估维度（0-10分）：
    1. 技术准确性
    2. 举例恰当性
    3. 知识系统性
    总分加权计算：0.6*1 + 0.2*2 + 0.2*3
```



## 一，1.20

标签： spring，设计模型

- IOC加载过程：

- Spring 中的 AOP
- 设计模式
- 多个系统，你如何设计



## 二，2.10

标签：RabbitMQ, Redis,MySql,线程池,性能优化

- 支付的过程中，支付时网络断了
- mq 消息堆积
- mq 顺序消息如何保证
- redis卡顿
- Java 线程池注意什么，核心线程数量，最大线程数
- 如何优化一个接口，做了什么 qps
- Mysql 如何找到慢sql，如何优化，那些手段
- Mysql 数据库中修改如何对它进行记录修改前，修改后 （多个角度，binlog）
- Mysql 中的某mvcc 原理 ==难==



### **一、消息堆积的常见原因**

1. **生产者流量过大**
   - 生产者发送消息的速率远超过消费者的处理能力。
   - 例如：秒杀活动、日志采集等场景。
2. **消费者处理能力不足**
   - 消费者处理逻辑复杂（如数据库操作、网络请求等），导致消费速度慢。
   - 消费者数量不足（如单线程消费）。
3. **消费者故障或未正确ACK**
   - 消费者未正确返回 `ack`（消息确认），导致消息重新入队，重复堆积。
   - 消费者进程崩溃或网络问题，导致消息未被消费。
4. **队列配置不合理**
   - 队列未设置消息过期时间（TTL），导致消息无限堆积。
   - 未配置死信队列（Dead Letter Exchange, DLX），无法自动处理异常消息。
5. **死信队列堆积**
   - 消息因重试次数过多或无法处理进入死信队列，但未及时处理死信队列中的消息。



### **二、处理消息堆积的解决方案**

#### **1. 紧急处理：快速消费堆积消息**

- **临时扩容消费者**

  - 增加消费者实例数量（水平扩展），提升消费速度。
  - 使用多线程消费模式（如一个消费者进程内启动多个线程并发处理消息）。

- **批量消费消息**

  - 在消费者代码中启用批量消费（如 `basic.qos` 设置 `prefetch_count`），一次拉取多条消息处理。

  ```bash
  // RabbitMQ 客户端示例（Java）
  channel.basicQos(100); // 每次预取 100 条消息
  ```

- **跳过非关键消息**

  - 如果是非关键业务（如日志），可以临时丢弃部分消息，优先保证核心业务。



#### **2. 优化消费者性能**

- **优化消费逻辑**
  - 减少单条消息处理时间（如异步化、缓存优化、数据库批量写入）。
  - 避免在消费者中执行耗时操作（如同步 RPC 调用）。
- **异步处理消息**
  - 将消息处理逻辑异步化，例如将任务提交到线程池或消息队列中。
- **合理使用消息确认机制**
  - 确保消费者正确处理消息后发送 `ack`，避免消息因未确认而重复投递。
  - 对于不需要严格顺序的消息，可以开启自动确认（`autoAck=true`），但需谨慎使用。

------

#### **3. 调整队列配置**

- **设置消息TTL（过期时间）**

  - 为队列或消息设置生存时间，超时的消息自动进入死信队列或被删除。

  ```bash
  # 创建队列时设置 TTL（单位：毫秒）
  rabbitmqadmin declare queue name=my_queue arguments='{"x-message-ttl": 60000}'
  ```

- **配置死信队列（DLX）**

  - 定义死信交换机和队列，处理无法消费的消息（如重试多次失败的消息）。

  ```bash
  # 创建队列时绑定死信交换机
  rabbitmqadmin declare queue name=my_queue arguments='{"x-dead-letter-exchange": "dlx_exchange"}'
  ```

- **限制队列最大长度**

  - 设置队列的最大消息数量或最大内存占用，防止无限堆积。

  ```bash
  # 限制队列最多存储 10000 条消息
  rabbitmqadmin declare queue name=my_queue arguments='{"x-max-length": 10000}'
  ```

------

#### **4. 生产者限流**

- **控制生产者速率**
  - 在生产者端限流，例如通过令牌桶算法控制消息发送速率。
  - 使用 RabbitMQ 的流量控制机制（如 `channel.flow`）。
- **启用生产者确认（Publisher Confirm）**
  - 确保消息成功到达 Broker，避免生产者重复发送消息。

------

#### **5. 监控与告警**

- **监控队列长度**
  - 使用 RabbitMQ Management 插件或 Prometheus + Grafana 监控队列堆积情况。
  - 设置阈值告警（如队列长度超过 1 万时触发告警）。
- **分析堆积原因**
  - 通过日志排查消费者异常（如频繁报错、超时）。
  - 检查网络延迟或 Broker 性能问题（如磁盘 IO 过高）。

------

#### **6. 处理历史堆积消息**

- **临时脚本快速消费**

  - 编写脚本批量拉取消息并直接写入数据库或日志文件（绕过业务逻辑）。
  - 使用 `rabbitmqadmin` 工具导出消息：

  ```shell
  rabbitmqadmin get queue=my_queue count=1000 > messages.json
  ```

- **重建队列**

  - 如果是非关键数据，可以临时删除队列并重新创建（谨慎操作！）。



### **三、预防消息堆积**

1. **合理设计队列**
   - 根据业务需求选择持久化（持久化消息会降低性能）。
   - 分业务拆分队列，避免单一队列压力过大。
2. **压力测试**
   - 上线前模拟生产者和消费者的压力，评估系统吞吐量。
3. **动态扩容能力**
   - 使用 Kubernetes 或云服务实现消费者自动扩缩容。
4. **消息削峰填谷**
   - 在生产者端使用本地缓存或限流，平滑突发流量。



### **总结**

消息堆积的核心解决思路是：

1. **快速止血**：扩容消费者、丢弃非关键消息。
2. **优化消费能力**：提升单消费者性能、增加并发。
3. **预防措施**：合理配置队列、监控告警、压力测试。

根据具体场景选择合适的方案，例如电商秒杀场景可能需要限流 + 异步处理，而日志采集场景可以容忍部分消息丢失。

----

### **一、线程池核心参数与工作流程**

Java 线程池通过 `ThreadPoolExecutor` 实现，其核心参数如下：

```java
ThreadPoolExecutor(
    int corePoolSize,      // 核心线程数
    int maximumPoolSize,   // 最大线程数
    long keepAliveTime,    // 非核心线程空闲存活时间
    TimeUnit unit,         // 时间单位
    BlockingQueue<Runnable> workQueue, // 任务队列
    RejectedExecutionHandler handler   // 拒绝策略
)
```

**工作流程**：

1. 提交任务时，优先使用核心线程处理。
2. 核心线程满后，任务进入队列等待。
3. 队列满后，创建非核心线程（直到达到最大线程数）。
4. 所有线程和队列均满时，触发拒绝策略。

------

### **二、核心线程数（corePoolSize）设置原则**

#### **1. 任务类型决定线程数**

- CPU 密集型任务（如计算、逻辑处理）：
  - 线程数 ≈ CPU 核心数 + 1（防止线程阻塞浪费资源）。
  - 示例：4 核 CPU → `corePoolSize = 5`。
- IO 密集型任务（如网络请求、文件读写）：
  - 线程数 ≈ 2 * CPU 核心数（利用线程等待 IO 的空闲时间）。
  - 示例：4 核 CPU → `corePoolSize = 8`。

#### **2. 动态调整**

- 使用 `setCorePoolSize()` 方法动态调整核心线程数（如根据业务高峰/低谷）。
- 默认情况下，核心线程即使空闲也不会被回收（需设置 `allowCoreThreadTimeOut(true)` 改变行为）。

------

### **三、最大线程数（maximumPoolSize）设置原则**

- **公式**：`maximumPoolSize = corePoolSize + 弹性扩展余量`。
- 场景示例：
  - **突发流量**：若任务量可能突然激增，可设置较大的 `maximumPoolSize`（如 `corePoolSize * 2`）。
  - **资源敏感型系统**：若服务器资源有限，需严格控制最大线程数，避免 OOM。
- **注意**：线程数过多会导致频繁上下文切换，反而降低性能。

------

### **四、任务队列（workQueue）选择**

| **队列类型**                              | **特点**                                                     | **适用场景**                       |
| ----------------------------------------- | ------------------------------------------------------------ | ---------------------------------- |
| **无界队列**（如 `LinkedBlockingQueue`）  | 队列无限增长，可能导致 OOM                                   | 任务量可控且拒绝策略要求不高的场景 |
| **有界队列**（如 `ArrayBlockingQueue`）   | 队列满后触发创建非核心线程                                   | 需要限制资源使用的场景             |
| **同步移交队列**（`SynchronousQueue`）    | 不存储任务，直接移交线程执行（需配合较大的 `maximumPoolSize`） | 高吞吐、短任务场景                 |
| **优先级队列**（`PriorityBlockingQueue`） | 按优先级处理任务                                             | 需要任务优先级的场景               |

------

### **五、拒绝策略（RejectedExecutionHandler）**

| **策略**                | **行为**                                               |
| ----------------------- | ------------------------------------------------------ |
| **AbortPolicy**（默认） | 直接抛出 `RejectedExecutionException`                  |
| **CallerRunsPolicy**    | 由提交任务的线程直接执行任务（降低提交速度，避免雪崩） |
| **DiscardPolicy**       | 静默丢弃新任务                                         |
| **DiscardOldestPolicy** | 丢弃队列中最旧的任务，重新提交新任务                   |

------

### **六、最佳实践与示例**

#### **1. 通用配置模板**

```java
int cpuCores = Runtime.getRuntime().availableProcessors();

ThreadPoolExecutor executor = new ThreadPoolExecutor(
    cpuCores + 1,                   // corePoolSize
    cpuCores * 2,                   // maximumPoolSize
    60, TimeUnit.SECONDS,           // keepAliveTime
    new LinkedBlockingQueue<>(1000),// 有界队列（容量1000）
    new ThreadFactoryBuilder().setNameFormat("task-pool-%d").build(), // 自定义线程名
    new CallerRunsPolicy()          // 拒绝策略
);
```

#### **2. 场景优化**

- Web 服务器请求处理（IO 密集型）：

  ```java
  corePoolSize = 2 * cpuCores;
  maximumPoolSize = 4 * cpuCores;
  workQueue = new LinkedBlockingQueue<>(2000);
  ```

- 批量数据处理（CPU 密集型）：

  ```java
  corePoolSize = cpuCores + 1;
  maximumPoolSize = cpuCores + 1; // 严格限制线程数
  workQueue = new SynchronousQueue<>(); // 无缓冲，直接执行
  ```

------

### **七、注意事项**

1. **避免无界队列**：防止任务堆积导致内存溢出（OOM）。

2. 监控线程池状态：

   ```java
   // 获取活跃线程数
   executor.getActiveCount();
   // 获取队列积压任务数
   executor.getQueue().size();
   ```

3. 优雅关闭线程池：

   ```java
   executor.shutdown();          // 停止接收新任务，等待已有任务完成
   executor.shutdownNow();       // 尝试立即终止所有任务（慎用）
   ```

4. **线程池隔离**：不同业务使用独立线程池，避免互相影响。

------

### **八、总结**

- **核心线程数**：由任务类型（CPU/IO 密集型）和 CPU 核心数决定。
- **最大线程数**：根据系统负载和资源限制动态调整。
- **队列选择**：优先使用有界队列，结合拒绝策略保护系统稳定性。
- **拒绝策略**：推荐 `CallerRunsPolicy` 或自定义策略，避免直接丢弃任务。

通过合理配置线程池参数，可以在高并发场景下实现资源高效利用与系统稳定性的平衡。



==备注==：在IO密集型任务中，推荐线程数约为CPU核心数的两倍，主要基于以下原因：

1. **利用IO等待时间**：
   - **阻塞期间CPU空闲**：当线程执行IO操作（如读写文件、网络请求）时，会进入阻塞状态，此时CPU可执行其他线程的任务。
   - **提高吞吐量**：通过增加线程数，CPU在等待一个线程的IO完成时，可切换到其他线程执行计算任务，减少空闲时间。
2. **经验公式与平衡点**：
   - **2倍核心数的由来**：假设线程有约50%的时间在等待IO，则双倍线程可让CPU在等待期间处理另一线程的任务，保持高利用率。
   - **避免过度切换**：过多的线程会增加上下文切换开销，两倍核心数是平衡利用率和切换成本的经验值。
3. **实际场景调整**：
   - **IO等待时间差异**：若IO延迟更高（如远程API调用），可适当增加线程数；若IO较快（如本地SSD），可减少线程数。
   - **系统资源限制**：需考虑内存、文件描述符等资源，避免因线程过多导致OOM或资源竞争。

**示例**：

- 4核CPU处理网络请求：
  - 设置8个线程，每个线程在等待响应时，CPU处理其他请求，提升并发能力。
- 调整依据：
  - 监控CPU利用率：若长期低于70%，可增加线程；若过高（>90%）或上下文切换频繁，则减少线程。

**总结**：两倍核心数是平衡IO等待和CPU利用的经验起点，实际需根据任务特性和系统监控动态调整。

-----

Redis 出现卡顿（延迟高、响应慢）通常由多种原因引起，需要结合具体场景排查。以下是常见原因及对应的解决方案：



### **一、常见原因及排查方法**

#### **1. 内存不足导致交换（SWAP）**

- **现象**：Redis 响应变慢，`redis-cli info memory` 显示 `used_memory` 接近或超过物理内存，`used_memory_rss` 异常高。

- 原因：

  - 物理内存不足，触发操作系统使用 SWAP 分区。
  - 大 Key（如单个 Key 存储数 MB 数据）或内存碎片化严重。

- 排查：

  ```bash
  # 查看内存使用
  redis-cli info memory | grep -E "used_memory|used_memory_rss|mem_fragmentation_ratio"
  
  # 检查大 Key（需谨慎，可能阻塞）
  redis-cli --bigkeys
  ```

- 解决：

  - 增加物理内存或优化数据存储（如拆分大 Key、使用更高效的数据结构）。
  - 配置 `maxmemory` 和淘汰策略（如 `allkeys-lru`），避免内存溢出。
  - 关闭 SWAP：`sudo swapoff -a`（临时）或调整 `vm.swappiness=1`（永久）。

------

#### **2. 持久化操作阻塞**

- **现象**：定时卡顿，与 RDB 快照或 AOF 重写时间点吻合。

- 原因：

  - **RDB 生成**：`bgsave` 或 `save` 时 fork 进程可能阻塞主线程（尤其内存大时）。
  - **AOF 重写**：AOF 重写期间占用大量磁盘 I/O。

- 排查：

  ```bash
  # 查看持久化状态
  redis-cli info persistence | grep -E "rdb_last_bgsave_status|aof_rewrite_in_progress"
  
  # 监控 fork 耗时
  redis-cli info stats | grep latest_fork_usec
  ```

- 解决：

  - 使用 `bgsave` 而非 `save`，避免主线程阻塞。
  - 关闭 `THP`（透明大页）：`echo never > /sys/kernel/mm/transparent_hugepage/enabled`。
  - 将持久化操作放到从节点执行。
  - 使用 SSD 提升磁盘 I/O 性能。

------

#### **3. 慢查询**

- **现象**：间歇性延迟，`redis-cli info stats` 中 `total_commands_processed` 增长缓慢。

- 原因：

  - 执行 `KEYS *`、`HGETALL` 等复杂度 O(N) 的命令。
  - 使用 Lua 脚本执行时间过长。

- 排查：

  ```bash
  # 查看慢查询日志（需提前配置）
  redis-cli config set slowlog-log-slower-than 10000  # 设置阈值（微秒）
  redis-cli slowlog get 10  # 查看最近10条慢查询
  ```

- 解决：

  - 避免使用 `KEYS *`，改用 `SCAN` 分批次遍历。
  - 优化复杂命令，如将多次 `HGET` 合并为 `HMGET`。
  - 拆分耗时 Lua 脚本，或使用 `SCRIPT KILL` 终止阻塞脚本。

------

#### **4. 网络或客户端问题**

- **现象**：Redis 服务端负载低，但客户端感知延迟高。

- 原因：

  - 网络带宽不足或延迟高。
  - 客户端连接数过多或未使用连接池。
  - 客户端使用阻塞操作（如 `BLPOP` 超时时间长）。

- 排查：

  ```bash
  # 查看客户端连接数
  redis-cli info clients | grep connected_clients
  
  # 监控网络延迟
  ping <redis-host>
  ```

- 解决：

  - 使用连接池管理客户端连接。
  - 优化客户端代码，避免阻塞操作。
  - 检查网络设备（如交换机、防火墙）或切换为低延迟网络。

------

#### **5. 主从同步或集群问题**

- **现象**：集群模式下部分节点延迟高，或主从复制延迟。

- 原因：

  - 主从节点网络不稳定。
  - 主节点生成 RDB 文件传输耗时。
  - 集群分片不均导致部分节点负载高。

- 排查：

  ```bash
  # 查看主从复制状态
  redis-cli info replication | grep -E "master_link_status|master_last_io_seconds_ago"
  
  # 检查集群分片
  redis-cli cluster slots
  ```

- 解决：

  - 优化主从节点网络（如部署在同一机房）。
  - 使用 `repl-diskless-sync yes` 减少 RDB 传输对磁盘的依赖。
  - 重新分配集群槽位，平衡负载。

------

### **二、系统级优化**

#### **1. 操作系统配置**

- 关闭透明大页（THP）：

  ```bash
  echo never > /sys/kernel/mm/transparent_hugepage/enabled
  ```

- 调整内核参数：

  ```bash
  # 提升网络性能
  sysctl -w net.core.somaxconn=65535
  sysctl -w vm.overcommit_memory=1
  ```

#### **2. 监控工具**

- 实时监控：

  ```bash
  # 查看 Redis 实时状态
  redis-cli --latency -h <host> -p <port>  # 延迟检测
  redis-cli monitor                        # 监控所有命令
  ```

- 外部工具：

  - Prometheus + Grafana + Redis Exporter。
  - 使用 `redis-stat` 或 `redis-cli --intrinsic-latency 100` 检测基线延迟。



### **三、总结**

Redis 卡顿的解决步骤：

1. **优先检查内存和持久化**：确认是否因内存不足或持久化操作导致阻塞。
2. **分析慢查询**：优化高复杂度命令。
3. **排查网络和客户端**：确保客户端合理使用连接池，避免阻塞操作。
4. **系统级调优**：关闭 THP、调整内核参数。
5. **集群优化**：平衡分片、优化主从同步。

若问题复杂，可结合 `redis-benchmark` 压测定位瓶颈，或使用 `perf` 工具分析 Redis 进程的系统调用。



-----

